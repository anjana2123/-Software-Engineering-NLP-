{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f43a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18e7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a23236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46570cda",
   "metadata": {},
   "source": [
    "### Simple Approcahes to Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dca2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "... though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "... well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ae9eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\nthough),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\nwell',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r' ',raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b39d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[ \\t\\n]+',raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0245f6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.split(r'\\W+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfceaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+|\\S\\w*', raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "584fb362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
     ]
    }
   ],
   "source": [
    " print (re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab84418",
   "metadata": {},
   "source": [
    "### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e987fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c3e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25101b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffea25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenizer.tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60486158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the wild events which were to follow this girl had no\\n'\n",
      " 'part at all; he never saw her again until all his tale was over.',\n",
      " 'And yet, in some indescribable way, she kept recurring like a\\n'\n",
      " 'motive in music through all his mad adventures afterwards, and the\\n'\n",
      " 'glory of her strange hair ran like a red thread through those dark\\n'\n",
      " 'and ill-drawn tapestries of the night.',\n",
      " 'For what followed was so\\nimprobable, that it might well have been a dream.',\n",
      " 'When Syme went out into the starlit street, he found it for the\\n'\n",
      " 'moment empty.',\n",
      " 'Then he realised (in some odd way) that the silence\\n'\n",
      " 'was rather a living silence than a dead one.',\n",
      " 'Directly outside the\\n'\n",
      " 'door stood a street lamp, whose gleam gilded the leaves of the tree\\n'\n",
      " 'that bent out over the fence behind him.',\n",
      " 'About a foot from the\\n'\n",
      " 'lamp-post stood a figure almost as rigid and motionless as the\\n'\n",
      " 'lamp-post itself.',\n",
      " 'The tall hat and long frock coat were black; the\\n'\n",
      " 'face, in an abrupt shadow, was almost as dark.',\n",
      " 'Only a fringe of\\n'\n",
      " 'fiery hair against the light, and also something aggressive in the\\n'\n",
      " 'attitude, proclaimed that it was the poet Gregory.',\n",
      " 'He had something\\n'\n",
      " 'of the look of a masked bravo waiting sword in hand for his foe.']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sents[171:181])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd1437",
   "metadata": {},
   "source": [
    "### Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "038d6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dfb7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last:i+1])\n",
    "            last = i+1\n",
    "    words.append(text[last:])\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "347dac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment(text, seg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ffb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = len(' '.join(list(set(words))))\n",
    "    return text_size + lexicon_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2748958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyou',\n",
       " 'see',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'see',\n",
       " 'thedogg',\n",
       " 'y',\n",
       " 'doyou',\n",
       " 'like',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'like',\n",
       " 'thedogg',\n",
       " 'y']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "segment(text, seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bd1824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text,seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ca4f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text,seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e2311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text,seg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ac184",
   "metadata": {},
   "source": [
    "### From lists to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef7bcb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We called him Tortoise because he taught us .'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "' '.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34b24cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We;called;him;Tortoise;because;he;taught;us;.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ';'.join(silly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ed1ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WecalledhimTortoisebecausehetaughtus.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ''.join(silly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c170deed",
   "metadata": {},
   "source": [
    "### String Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3496bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'cat'\n",
    "sentence = \"\"\"hello world\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95615357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog -> 4 ;\n",
      "cat -> 3 ;\n",
      "snake -> 1 ;\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])\n",
    "for word in fdist:\n",
    "    print (word, '->', fdist[word], ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1944e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog->4;\n",
      "cat->3;\n",
      "snake->1;\n"
     ]
    }
   ],
   "source": [
    "for word in fdist:\n",
    "    print ('%s->%d;' % (word, fdist[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c57eb0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lee wants a sandwich for lunch'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%s wants a %s %s\" % (\"Lee\", \"sandwich\", \"for lunch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff262f25",
   "metadata": {},
   "source": [
    "### Lining Things Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb142ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy for 9375 words: 34.1867%'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, total = 3205, 9375\n",
    "\"accuracy for %d words: %2.4f%%\" % (total, 100 * count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ef4e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    print ('%-16s' % 'Category')\n",
    "    for word in words: # column headings\n",
    "        print ('%6s' % word)\n",
    "    print\n",
    "    for category in categories:\n",
    "        print ('%-16s' % category) # row heading\n",
    "        for word in words: # for each word\n",
    "            print ('%6d' % cfdist[category][word]) # print table cell\n",
    "        print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5c918c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category        \n",
      "   can\n",
      " could\n",
      "   may\n",
      " might\n",
      "  must\n",
      "  will\n",
      "news            \n",
      "    93\n",
      "    86\n",
      "    66\n",
      "    38\n",
      "    50\n",
      "   389\n",
      "religion        \n",
      "    82\n",
      "    59\n",
      "    78\n",
      "    12\n",
      "    54\n",
      "    71\n",
      "hobbies         \n",
      "   268\n",
      "    58\n",
      "   131\n",
      "    22\n",
      "    83\n",
      "   264\n",
      "science_fiction \n",
      "    16\n",
      "    49\n",
      "     4\n",
      "    12\n",
      "     8\n",
      "    16\n",
      "romance         \n",
      "    74\n",
      "   193\n",
      "    11\n",
      "    51\n",
      "    45\n",
      "    43\n",
      "humor           \n",
      "    16\n",
      "    30\n",
      "     8\n",
      "     8\n",
      "     9\n",
      "    13\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist((genre, word)\n",
    "for genre in brown.categories()\n",
    "for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "tabulate(cfd, modals, genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73a5a1",
   "metadata": {},
   "source": [
    "### Text Wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42cd5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5),\n",
      "all (3),\n",
      "is (2),\n",
      "said (4),\n",
      "and (3),\n",
      "done (4),\n",
      ", (1),\n",
      "more (4),\n",
      "is (2),\n",
      "said (4),\n",
      "than (4),\n",
      "done (4),\n",
      ". (1),\n"
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',','more', 'is', 'said', 'than', 'done', '.']\n",
    "for word in saying:\n",
    "    print (word, '(' + str(len(word)) + '),')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfbfcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import fill\n",
    "format = '%s (%d),'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d16289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more\n",
      "(4), is (2), said (4), than (4), done (4), . (1),\n"
     ]
    }
   ],
   "source": [
    "pieces = [format % (word, len(word)) for word in saying]\n",
    "output = ' '.join(pieces)\n",
    "wrapped = fill(output)\n",
    "print (wrapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a70404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
